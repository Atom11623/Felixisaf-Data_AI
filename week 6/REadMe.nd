{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09d2a36a-0e9c-4d24-b1fa-d544e8ddd8d1",
   "metadata": {},
   "source": [
    "# Twitter Data Preprocessing Project\n",
    "\n",
    "## Project Overview\n",
    "This project involves preprocessing Twitter data from the **WeRateDogs dataset** provided by Udacity. The dataset consists of tweets with various metadata, including timestamps, sources, and text content. The goal is to clean and preprocess the dataset for Natural Language Processing (NLP) tasks such as sentiment analysis, text classification, or exploratory data analysis.\n",
    "\n",
    "## Dataset Information\n",
    "- **Dataset Name:** WeRateDogs Twitter Dataset (from Udacity)\n",
    "- **File Used:** `twitter.csv`\n",
    "- **Primary Column:** `text` (contains tweet content)\n",
    "- **Other Processed Columns:** `source`\n",
    "- **Columns Removed:**\n",
    "  - `in_reply_to_status_id`\n",
    "  - `in_reply_to_user_id`\n",
    "  - `timestamp`\n",
    "  - `retweeted_status_id`\n",
    "  - `retweeted_status_user_id`\n",
    "  - `retweeted_status_timestamp`\n",
    "  - `expanded_urls`\n",
    "\n",
    "## Preprocessing Steps\n",
    "The dataset undergoes several preprocessing steps to ensure clean and structured text for analysis:\n",
    "\n",
    "1. **Lowercasing**: Convert all text to lowercase to maintain uniformity.\n",
    "2. **Removing URLs**: Extract and remove any links (`http://` or `https://`) from the tweets.\n",
    "3. **Removing Punctuation**: Eliminate unnecessary punctuation using `string.punctuation`.\n",
    "4. **Removing Stopwords**: Filter out common words (e.g., \"and\", \"the\", \"is\") using the `nltk` library.\n",
    "5. **Removing Emojis**: Use regex to remove emojis and pictographs.\n",
    "6. **Lemmatization**: Convert words to their base form (e.g., \"running\" → \"run\") using `spaCy`.\n",
    "7. **Cleaning Source Column**: Extract the platform name (e.g., \"Twitter for iPhone\") from HTML-formatted sources.\n",
    "\n",
    "## Dependencies\n",
    "The script requires the following Python libraries:\n",
    "- `pandas` – for handling the dataset\n",
    "- `string` – for punctuation removal\n",
    "- `re` – for regex-based text cleaning\n",
    "- `nltk` – for stopword removal\n",
    "- `spacy` – for text lemmatization\n",
    "\n",
    "To install missing dependencies, run:\n",
    "```bash\n",
    "pip install pandas nltk spacy\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "This script will output a cleaned version of the dataset as `cleaned_twitter.csv`.\n",
    "\n",
    "## Output\n",
    "- **Final Processed File:** `cleaned_twitter.csv`\n",
    "- **Changes Applied:** All preprocessing steps listed above.\n",
    "\n",
    "## Author\n",
    "- **Project by:** [Your Name]\n",
    "- **Dataset Source:** Udacity (WeRateDogs Twitter Data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f6db3-2cd5-474c-b6ae-cdfa6ccc8c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
